---
title: "solutions"
author: "Stephen Winkler"
date: "April 9, 2016"
output: html_document

---
### Problem 1: Data Wrangling and Viz Refresher

The file [democracy.csv](https://raw.githubusercontent.com/POLS503/pols_503_sp15/master/data/democracy.csv) contains data from Przeworski et. al, *Demoracy and Deveolpment: Political Institutions and Well-Being in the Worlds, 1950-1990* [^1].
The data have been slightly recoded, to make higher values indicate higher levels of political liberty and democracy.

| Variable | Description                      |
|:---------|:---------------------------------|
| `COUNTRY` | numerical code for each country |
| `CTYNAME` | name of each country |
| `REGION` | name of region containing country |
| `YEAR` | year of observation |
| `GDPW`   |  GDP per capita in real international prices |
| `EDT`    |  average years of education |
| `ELF60`  |  ethnolinguistic fractionalization |
| `MOSLEM` |  percentage of Muslims in country |
| `CATH`   |  percentage of Catholics in country |
| `OIL`    |  whether oil accounts for 50+\% of exports |
| `STRA`   |  count of recent regime transitions |
| `NEWC`   |  whether county was created after 1945 |
| `BRITCOL` |  whether country was a British colony |
| `POLLIB` | degree of political liberty (1--7 scale, rising in political liberty) |
| `CIVLIB` | degree of civil liberties (1--7 scale, rising in civil liberties) |
| `REG`    | presence of democracy (0=non-democracy, 1=democracy)|

For these questions use **ggplot2** for plotting, and **dplyr** and **tidyr** for the data manipulation.
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(knitr)
```
a. Load the democracy data frame
```{r}
democracy <- read.csv(file = "democracy.csv", stringsAsFactors = FALSE, na.strings = ".")
```

a. Create a data frame with statistics (means, medians) for all variables. Instead of doing this with `summary`, use **dplyr** and **tidyr** as shown in the example [https://uw-pols501.github.io/pols_501_wi16/lessons/gapminder_intro_to_dplyr_tidyr.html#plotting]. 
```{r}
dem_by_variable <- 
  democracy %>%
  gather(variable, value, -COUNTRY, -YEAR, -REGION, -CTYNAME)
dem_by_variable

dem_summary_stats <- dem_by_variable %>%
  group_by(variable, CTYNAME) %>%
  summarise(mean = mean(value),
            median = median(value)) %>%
  gather(stat, value, -CTYNAME, -variable) %>%
  ungroup() %>%
  unite(variable_stat, variable, stat) %>%
  spread(variable_stat, value)
```

Print this table using the function `kable` in the **knitr** package, an the code chunk option `results='asis`. See the [R Markdown Help](http://rmarkdown.rstudio.com/authoring_rcodechunks.html).

```{r, results='asis'}
kable(dem_summary_stats, format = "markdown")
```

d. Create a histogram for political liberties in which each unique
value of the variable is in its own bin.
```{r}
ggplot(democracy, aes(x = POLLIB)) + geom_histogram(binwidth = 1)
```
e. Create a histogram for GDP per capita.
```{r}
ggplot(democracy, aes(x = GDPW)) + geom_histogram()
```
f. Create a histogram for **log** GDP per capita. How is this histogram different than the one for GDP per capita when it was not logged.
- It is not right skewed, more normal distribution.
```{r}
ggplot(democracy, aes(x = log(GDPW))) + geom_histogram()
```
g. Plot political liberties against GDP per capita. If you use 
   a scatterplot, there will be overlap. Figure out a way to plot
   these two variables so that the pattern (if any) between them is 
   clear. There could be multiple ways to do this, and not necessarily a scatterplot.
```{r}
ggplot(democracy, aes(x = POLLIB, y = GDPW)) + 
  geom_boxplot(aes(group = POLLIB))
```

i. Plot political liberties against **log** GDP per
   capita, using the same method as the previous question.  How is the relationship different than  when GDP per capita was not logged?
- There are far fewer outliers. Also, the y axis is easier to understand as log units. 
```{r}
ggplot(democracy, aes(x = POLLIB, y = log(GDPW))) + 
  geom_boxplot(aes(group = POLLIB))
```
j. Create a boxplot of GDP per capita for oil producing and non-oil producing nations. Use **ggplot2**. This should be one plot, not two separate plots.
```{r}
ggplot(democracy, aes(x = OIL, y = GDPW)) + geom_boxplot(aes(group = OIL))
```
k. Calculate the mean GDP per capita in countries with at least 40 percent Catholics. How does it compare to mean GDP per capita for all countries? Remember to check the units of Catholic.
- The mean GDP per cap in predominantly Catholic countries is higher than in all countries. 
```{r}
democracy %>%
  filter(CATH >= 40) %>%
 summarize(mean_CATH40plus = mean(GDPW))
   
summarize(democracy, mean = mean(GDPW))

```
l. Calculate the average GDP per capita in countries with greater than
   60% ethnolinguistic fractionalization, less than 60%, and missing
   ethnolinguistic fractionalization.  Hint: you can calculate this
   with the **dplyr** verbs: `mutate`, `group_by` and `summarize`.
   
```{r}
democracy %>%
  filter(ELF60 > .60) %>%
  summarize(mean_GDP_ELF60plus = mean(GDPW))
 
democracy%>%
   filter(ELF60 < .60) %>%
  summarize(mean_GDP_ELF60less = mean(GDPW))

democracy%>%
   filter(is.na(ELF60)) %>%
  summarize(mean_GDP_ELF60NA = mean(GDPW))
```

m. For all years, calculate the median of the country average years of education all countries? Return this as a data-frame. Hint: use **dplyr** functions: `group_by`, `filter`, `summarize`. Plot the median of the years of education for all years using a line. Also show the original data.

```{r}
median_EDT_by_YEAR <- democracy %>% 
  group_by(YEAR) %>%
  summarize(median_EDT = median(EDT, na.rm = TRUE))
median_EDT_by_YEAR

median_EDT_by_YEAR_plot <- ggplot(median_EDT_by_YEAR, aes(x = YEAR, y = median_EDT)) + geom_point() + geom_smooth(method = "lm")
median_EDT_by_YEAR_plot

```

o. Repeat the previous question but group by both year and democracy. Plot separate lines for democracies and non-democries and the original data. Use color to differentiate democracies and non-democracies.

```{r}
median_EDT_by_YEAR <- democracy %>% 
  group_by(YEAR, REG) %>%
  summarize(median_EDT = median(EDT, na.rm = TRUE))
median_EDT_by_YEAR

median_EDT_by_YEAR_plot <- ggplot(median_EDT_by_YEAR, aes(x = YEAR, y = median_EDT)) + geom_point(aes(colour = factor(REG))) + geom_smooth(method = "lm")
median_EDT_by_YEAR_plot

```

n. Which country was (or countries were) closest to the median years of education in 1985 among all countries? Hint: use **dplyr** functions: `filter`, `mutate`, `arrange`, and `slice`. 

```{r}
democracy %>%
  filter(YEAR == 1985, !is.na(EDT)) %>%
  arrange(EDT) %>%
  slice(113/2)
```

q. What were the 25th and 75th percentiles of ethnolinguistic fractionalization for new and old countries? Return this as a data frame with columns `NEWC`, `ELF60_p25`, and `ELF60_p75`. Print it as a nicely formatted table with `kable`.
```{r}
ELF60_percentiles <- 
  democracy %>%
  group_by(NEWC) %>%
  summarize(ELF60_p25 = quantile(ELF60, probs = .25, na.rm = TRUE),
            ELF60_p75 = quantile(ELF60, probs = .75, na.rm = TRUE))

kable(ELF60_percentiles, format = "markdown")

```

### Problem 2: Plotting data and regressions

This question will use a dataset included with R

```{r}
data("anscombe")
```

The dataset consists of 4 seperate datasets each with an $x$ and $y$ variable.[^anscombe]
The original dataset is not a tidy dataset.
The following code creates a tidy dataset of the anscombe data that is easier to analyze than the 
```{r}
library("dplyr")
library("tidyr")
anscombe2 <- anscombe %>%
	mutate(obs = row_number()) %>%
	gather(variable_dataset, value, - obs) %>%
	separate(variable_dataset, c("variable", "dataset"), sep = 1L) %>%
	spread(variable, value) %>%
	arrange(dataset, obs)
```

a. For each dataset: calculate the mean and standard deviations of x and y, and correlation between x and y, and run a linear regression between x and y for each dataset. How similar do you think that these datasets will look?
- They will look very similar because the correlation and regressions are similar in each. 
```{r}
anscombe2 %>%
  filter(dataset == 1) %>%
  summarize(mean_x = mean(x),
            mean_y = mean(y),
            sd_x = sd(x),
            sd_y = sd(y),
            cor(x, y)) 
reg1 <- lm(x ~ y, data = filter(anscombe2, dataset == 1))
reg1
anscombe2 %>%
  filter(dataset == 2) %>%
  summarize(mean_x = mean(x),
            mean_y = mean(y),
            sd_x = sd(x),
            sd_y = sd(y),
            cor(x, y)) 
reg2 <- lm(x ~ y, data = filter(anscombe2, dataset == 2))
reg2
anscombe2 %>%
  filter(dataset == 3) %>%
  summarize(mean_x = mean(x),
            mean_y = mean(y),
            sd_x = sd(x),
            sd_y = sd(y),
            cor(x, y)) 
reg3 <- lm(x ~ y, data = filter(anscombe2, dataset == 3))
reg3
anscombe2 %>%
  filter(dataset == 4) %>%
  summarize(mean_x = mean(x),
            mean_y = mean(y),
            sd_x = sd(x),
            sd_y = sd(y),
            cor(x, y)) 
reg4 <- lm(x ~ y, data = filter(anscombe2, dataset == 4))
reg4
```

b. Create a scatter plot of each dataset and its linear regression fit. Hint: you can do this easily with facet_wrap.
```{r}

anscombe_plot1 <- ggplot(aes(x = x, y = y),
                         data = filter(anscombe2, dataset == 1)) + 
  geom_point() + geom_smooth(method = "lm")
anscombe_plot1
anscombe_plot2 <- ggplot(aes(x = x, y = y),
                         data = filter(anscombe2, dataset == 2)) + 
  geom_point() + geom_smooth(method = "lm")
anscombe_plot2
anscombe_plot3 <- ggplot(aes(x = x, y = y),
                         data = filter(anscombe2, dataset == 3)) + 
  geom_point() + geom_smooth(method = "lm")
anscombe_plot3
anscombe_plot4 <- ggplot(aes(x = x, y = y),
                         data = filter(anscombe2, dataset == 4)) + 
  geom_point() + geom_smooth(method = "lm")
anscombe_plot4

```

### Problem 3: Predicting Sprint Times
In a 2004 paper in *Nature*, Tatem et al. estimate the trend lines of sprint times for men and women using the winning times of the 100-meters in the Olympics.[^sprint1] They report that using current trends, in the 2156 Olympics, the women's 100-meter will have a faster time.[^sprint2]

The dataset includes the winning times from the 100-meter dash for both men and women for all Olympics 1900-2012 and Track & Field World Championships finals 1976-2015.

| Variable | Description |
|:---|:---|
| `year` | Year of the Olympics or World Championships |
| `time` | Winning time |
| `women` | 1 if women's race; 0 if men's race |
| `olympics` | 1 if in the olympics; 0 if in the World Championships |

Load the data into R from the csv file:
```{r}
sprinters <- read.csv("sprinters.csv")
```

a. The referenced paper only used data from the Olympics 2004 and before. Create a new dataset named `sprinters_orig` with only those observations.
```{r}
sprinters_orig <-
  filter(sprinters,
         year <= 2004,
         olympics == 1)
```

b. Run the regressions
```{r}
library("dplyr")
mod1 <- lm(time ~ year + women, data = sprinters_orig)
mod2 <- lm(time ~ year * women, data = sprinters_orig)
mod3 <- lm(time ~ year, data = filter(sprinters_orig, women == 1))
mod4 <- lm(time ~ year, data = filter(sprinters_orig, women == 0))
```

Interpret each regression. How are they similar or different in their 
slopes? Plot each of these using the **texreg** package.

```{r}
library("texreg")
htmlreg(list(mod1, mod2, mod3, mod4), stars = numeric(),
        caption = "Trends in Winning Times in the Olympic 100-meter dash, 1896-2004")
```

c. Plot the fitted values of these regressions against the original values. The function `augment` in the **broom** package is useful for this. See examples [here](https://uw-pols501.github.io/pols_501_wi16/lessons/cov_cor_regression) or [here](https://uw-pols503.github.io/pols_503_sp16/regressions_in_R.html) for examples.
```{r}
library(tidyr)
tidy(mod1)
tidy(mod2)
tidy(mod3)
tidy(mod4)
fitted_mod1 <- augment(mod1)
fitted_mod2 <- augment(mod2)                  
fitted_mod3 <- augment(mod3)
fitted_mod4 <- augment(mod4)

ggplot(fitted_mod1, aes(x = year )) +
  geom_point(aes(y = time)) +
  geom_line(aes(y = .fitted))
ggplot(fitted_mod2, aes(x = year )) +
  geom_point(aes(y = time)) +
  geom_line(aes(y = .fitted))
ggplot(fitted_mod3, aes(x = year )) +
  geom_point(aes(y = time)) +
  geom_line(aes(y = .fitted))
ggplot(fitted_mod4, aes(x = year )) +
  geom_point(aes(y = time)) +
  geom_line(aes(y = .fitted))

```

d. Use the function `predict` to predict the times of men and women in the 2156 Olympics. Is this plausible?
- No, it can't decrease exponentially. 
```{r}
new_predict <- data.frame(women = c(1,0),
                          year = 2156)
predict(mod1, newdata = new_predict)

```

e. Calculate the square root of the mean of the squared residuals (root mean squared error or RMSE) for the regression `time ~ year * women`.
   Predict the values for the years after 2004 for both Olympics and World Championships. What are the root mean squared residuals for these predictions?
   Is it surprising that the RMSE for the predictions out of
   the sample are lower than those in the sample? 
##??
```{r}

```

   

[^1]: Przeworski, Adam, Michael E. Alvarez, Jose Antonio Cheibub, and Fernando Limongi. 2000. *Democracy and Development: Political Institutions and Well-Being in the World, 1950-1990*. Cambridge University Press.
[^anscombe]: These data are from: Anscombe, F. J. (1973). "Graphs in Statistical Analysis". *American Statistician* 27 (1): 17â€“21.
[^sprint1]: Andrew J. Tatem, Carlos A. Guerra, Peter M. Atkinson & Simon I. Hay. 2004. "Athletics:  Momentous sprint at the 2156 Olympics?" *Nature.* <https://dx.doi.org/10.1038/431525>
[^sprint2]: I've read the short article several times. I still can't tell whether it is tongue in cheek.
